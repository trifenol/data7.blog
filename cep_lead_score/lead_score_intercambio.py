# -*- coding: utf-8 -*-
"""lead_score_intercambio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qym_zxO_YYrNplrfvO3iRPE60xQ-bTSc
"""

"""
Lead Scoring para Intercâmbio usando CEP + Renda (Bayesiano)

Modelo: Estimativa bayesiana de renda por região (CEP) para priorizar leads
com maior probabilidade de conversão.

Arquivos de entrada:
- interesse.csv  -> data_interesse, cpf, email, cep
- formulario.csv -> data_resposta, cpf, intervalo_renda
- compras.csv    -> data_compra, cpf, destino, cep

Saída:
- leads_scoreados.csv: base de interesse com score_final, renda_estimada, etc.
"""

import numpy as np
import pandas as pd
import re
import matplotlib.pyplot as plt

pd.set_option("display.max_columns", 50)
pd.set_option("display.width", 140)


# ============================================================================
# 1. Funções de limpeza
# ============================================================================

def limpar_cpf(cpf):
    """Remove não-numéricos e normaliza para 11 dígitos."""
    if pd.isna(cpf):
        return np.nan
    cpf_str = re.sub(r"\D", "", str(cpf))
    # CPFs com menos de 11 dígitos provavelmente perderam zeros à esquerda
    if 9 <= len(cpf_str) <= 11:
        cpf_str = cpf_str.zfill(11)
    return cpf_str if len(cpf_str) == 11 else np.nan


def limpar_cep(cep):
    """Remove não-numéricos e normaliza para 8 dígitos."""
    if pd.isna(cep):
        return np.nan
    cep_str = re.sub(r"\D", "", str(cep))
    # CEPs com 7 dígitos provavelmente perderam o zero à esquerda
    if len(cep_str) == 7:
        cep_str = "0" + cep_str
    return cep_str if len(cep_str) == 8 else np.nan


def mapear_renda(valor):
    """
    Converte faixas textuais de renda para escala 1-5.

    1: até R$2.000
    2: R$2.000-4.000
    3: R$4.000-8.000
    4: R$8.000-12.000
    5: acima de R$12.000
    """
    if pd.isna(valor):
        return np.nan

    v = str(valor).strip().lower()
    digits = re.sub(r"\D", "", v)

    if "-r$2.000" in v or "ate 2000" in v or "até 2.000" in v or digits == "2000":
        return 1
    if "2000" in digits and "4000" in digits:
        return 2
    if "4000" in digits and "8000" in digits:
        return 3
    if "8000" in digits and "12000" in digits:
        return 4
    if "+r$12000" in v or "acima de" in v or ("12000" in digits and "8000" not in digits):
        return 5

    return np.nan


def adicionar_niveis_cep(df):
    """Adiciona colunas cep5, cep3, cep2."""
    df = df.copy()
    df["cep5"] = df["cep"].str[:5]
    df["cep3"] = df["cep"].str[:3]
    df["cep2"] = df["cep"].str[:2]
    return df


# ============================================================================
# 2. Modelo Bayesiano de Renda por CEP
# ============================================================================

def calcular_stats_bayesianas(df, col_cep, col_renda, media_global):
    """
    Calcula média bayesiana de renda por nível de CEP.

    Aplica shrinkage: regiões com poucos dados são puxadas para a média global.
    """
    stats = (
        df.groupby(col_cep)[col_renda]
        .agg(["count", "mean", "std"])
        .rename(columns={"count": "n_obs", "mean": "media_local", "std": "std"})
        .reset_index()
        .rename(columns={col_cep: "chave_cep"})
    )

    # k = peso do prior (média global)
    # Menos observações → mais shrinkage
    def calcular_k(n):
        if n >= 50:
            return 1
        elif n >= 10:
            return 3
        else:
            return 5

    stats["k"] = stats["n_obs"].apply(calcular_k)

    # Média bayesiana: (n * média_local + k * média_global) / (n + k)
    stats["media_bayes"] = (
        (stats["n_obs"] * stats["media_local"] + stats["k"] * media_global)
        / (stats["n_obs"] + stats["k"])
    )

    # Confiança: proporção do dado local na estimativa
    stats["confianca"] = stats["n_obs"] / (stats["n_obs"] + stats["k"])

    return stats[["chave_cep", "media_bayes", "confianca", "n_obs"]]


class ModeloRendaCEP:
    """Modelo bayesiano hierárquico de renda por CEP."""

    def __init__(self):
        self.media_global = None
        self.stats_cep5 = None
        self.stats_cep3 = None
        self.stats_cep2 = None

    def fit(self, df, col_renda="intervalo_renda_num"):
        """
        Treina o modelo usando dados de formulário.

        IMPORTANTE: usar todos os respondentes do formulário,
        não apenas compradores (evita selection bias).
        """
        df = adicionar_niveis_cep(df)

        self.media_global = df[col_renda].mean()
        print(f"Média global de renda: {self.media_global:.3f}")

        self.stats_cep5 = calcular_stats_bayesianas(df, "cep5", col_renda, self.media_global)
        self.stats_cep3 = calcular_stats_bayesianas(df, "cep3", col_renda, self.media_global)
        self.stats_cep2 = calcular_stats_bayesianas(df, "cep2", col_renda, self.media_global)

        print(f"CEPs únicos - cep5: {len(self.stats_cep5)}, cep3: {len(self.stats_cep3)}, cep2: {len(self.stats_cep2)}")

        return self

    def predict(self, df):
        """
        Aplica o modelo, usando fallback hierárquico:
        CEP-5 → CEP-3 → CEP-2 → média global
        """
        df = adicionar_niveis_cep(df)

        # Joins com cada nível
        df = df.merge(
            self.stats_cep5.rename(columns={"media_bayes": "media_cep5", "confianca": "conf_cep5"}),
            left_on="cep5", right_on="chave_cep", how="left"
        ).drop(columns=["chave_cep", "n_obs"], errors="ignore")

        df = df.merge(
            self.stats_cep3.rename(columns={"media_bayes": "media_cep3", "confianca": "conf_cep3"}),
            left_on="cep3", right_on="chave_cep", how="left"
        ).drop(columns=["chave_cep", "n_obs"], errors="ignore")

        df = df.merge(
            self.stats_cep2.rename(columns={"media_bayes": "media_cep2", "confianca": "conf_cep2"}),
            left_on="cep2", right_on="chave_cep", how="left"
        ).drop(columns=["chave_cep", "n_obs"], errors="ignore")

        # Fallback hierárquico
        df["renda_estimada"] = df["media_cep5"].fillna(df["media_cep3"]).fillna(df["media_cep2"]).fillna(self.media_global)

        df["confianca"] = df["conf_cep5"].fillna(df["conf_cep3"]).fillna(df["conf_cep2"]).fillna(0.3)

        df["nivel_usado"] = np.select(
            [df["media_cep5"].notna(), df["media_cep3"].notna(), df["media_cep2"].notna()],
            ["CEP-5", "CEP-3", "CEP-2"],
            default="GLOBAL"
        )

        # Score final: 90% renda (normalizada 0-1) + 10% confiança
        df["score_final"] = ((df["renda_estimada"] - 1) / 4) * 90 + df["confianca"] * 10

        # Limpar colunas intermediárias
        cols_drop = ["media_cep5", "media_cep3", "media_cep2", "conf_cep5", "conf_cep3", "conf_cep2"]
        df = df.drop(columns=[c for c in cols_drop if c in df.columns])

        return df


# ============================================================================
# 3. Avaliação do Modelo
# ============================================================================

def avaliar_predicao_renda(df, col_real="intervalo_renda_num", col_pred="renda_estimada"):
    """Avalia qualidade da predição de renda."""
    print("\n" + "=" * 60)
    print("AVALIAÇÃO: Predição de Renda")
    print("=" * 60)

    corr = df[[col_real, col_pred]].corr().iloc[0, 1]
    print(f"\nCorrelação real x estimada: {corr:.3f}")

    # Por decil de score
    df["decil"] = pd.qcut(df["score_final"], q=10, labels=False, duplicates="drop")

    stats = (
        df.groupby("decil")
        .agg(
            renda_real=(col_real, "mean"),
            renda_estimada=(col_pred, "mean"),
            n=("cpf", "count")
        )
        .sort_index(ascending=False)
    )

    print("\nRenda média por decil (9 = maior score):")
    print(stats.to_string())

    # Precision@K para alta renda
    df["alta_renda"] = (df[col_real] >= 4).astype(int)
    baseline = df["alta_renda"].mean()

    print(f"\n--- Precision@K (alta renda = faixa 4 ou 5) ---")
    print(f"Baseline: {baseline:.1%}")

    for k in [50, 100, 200]:
        if k > len(df):
            continue
        top_k = df.nlargest(k, "score_final")
        precision = top_k["alta_renda"].mean()
        lift = precision / baseline if baseline > 0 else np.nan
        print(f"K={k:4d} | Precision: {precision:.1%} | Lift: {lift:.2f}x")

    return stats


def avaliar_conversao(df):
    """Avalia capacidade do score de prever conversão."""
    print("\n" + "=" * 60)
    print("AVALIAÇÃO: Predição de Conversão")
    print("=" * 60)

    df["decil"] = pd.qcut(df["score_final"], q=10, labels=False, duplicates="drop")

    stats = (
        df.groupby("decil")
        .agg(
            taxa_conversao=("comprou", "mean"),
            n=("cpf", "count"),
            score_medio=("score_final", "mean")
        )
        .sort_index(ascending=False)
    )

    print("\nTaxa de conversão por decil (9 = maior score):")
    print(stats.to_string())

    # Score médio: comprou vs não comprou
    comparativo = df.groupby("comprou").agg(
        score_medio=("score_final", "mean"),
        n=("cpf", "count")
    )
    print("\nScore médio por grupo:")
    print(comparativo.to_string())

    # Lift no top decil
    baseline = df["comprou"].mean()
    top_decil = df[df["decil"] == df["decil"].max()]
    top_conv = top_decil["comprou"].mean()
    lift = top_conv / baseline if baseline > 0 else np.nan

    print(f"\nBaseline (conversão geral): {baseline:.2%}")
    print(f"Top decil (conversão):      {top_conv:.2%}")
    print(f"Lift:                       {lift:.2f}x")

    return stats


def plotar_resultados(df_validacao, df_interesse):
    """Gera visualizações dos resultados."""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Plot 1: Renda real por decil
    df_validacao["decil"] = pd.qcut(df_validacao["score_final"], q=10, labels=False, duplicates="drop")
    renda_por_decil = df_validacao.groupby("decil")["intervalo_renda_num"].mean()

    axes[0].plot(renda_por_decil.index, renda_por_decil.values, marker="o", linewidth=2)
    axes[0].set_xlabel("Decil de score (9 = maior)")
    axes[0].set_ylabel("Renda média real (1-5)")
    axes[0].set_title("Validação: Renda Real por Decil de Score")
    axes[0].invert_xaxis()
    axes[0].grid(True, alpha=0.3)

    # Plot 2: Conversão por decil
    df_interesse["decil"] = pd.qcut(df_interesse["score_final"], q=10, labels=False, duplicates="drop")
    conv_por_decil = df_interesse.groupby("decil")["comprou"].mean() * 100

    axes[1].bar(conv_por_decil.index, conv_por_decil.values, color="steelblue", edgecolor="black")
    axes[1].set_xlabel("Decil de score (9 = maior)")
    axes[1].set_ylabel("Taxa de conversão (%)")
    axes[1].set_title("Backtest: Conversão por Decil de Score")
    axes[1].invert_xaxis()
    axes[1].axhline(df_interesse["comprou"].mean() * 100, color="red", linestyle="--", label="Baseline")
    axes[1].legend()
    axes[1].grid(True, alpha=0.3, axis="y")

    plt.tight_layout()
    plt.savefig("resultados_lead_score.png", dpi=150)
    plt.show()
    print("\nGráfico salvo: resultados_lead_score.png")


def plotar_analises_adicionais(df_validacao, df_interesse, df_treino):
    """Gera visualizações adicionais para análise aprofundada."""

    # Preparar dados
    df_interesse["decil"] = pd.qcut(df_interesse["score_final"], q=10, labels=False, duplicates="drop")

    fig = plt.figure(figsize=(16, 12))

    # =========================================================================
    # 1. Distribuição de Scores (Conversores vs Não-Conversores)
    # =========================================================================
    ax1 = fig.add_subplot(2, 3, 1)

    scores_conv = df_interesse[df_interesse["comprou"] == 1]["score_final"]
    scores_nao_conv = df_interesse[df_interesse["comprou"] == 0]["score_final"]

    ax1.hist(scores_nao_conv, bins=30, alpha=0.6, label=f"Não converteu (n={len(scores_nao_conv):,})",
             color="gray", density=True)
    ax1.hist(scores_conv, bins=30, alpha=0.7, label=f"Converteu (n={len(scores_conv):,})",
             color="green", density=True)
    ax1.axvline(scores_conv.mean(), color="darkgreen", linestyle="--", linewidth=2)
    ax1.axvline(scores_nao_conv.mean(), color="dimgray", linestyle="--", linewidth=2)
    ax1.set_xlabel("Score")
    ax1.set_ylabel("Densidade")
    ax1.set_title("Distribuição de Scores")
    ax1.legend(loc="upper left")
    ax1.grid(True, alpha=0.3)

    # =========================================================================
    # 2. Curva de Lift Acumulado
    # =========================================================================
    ax2 = fig.add_subplot(2, 3, 2)

    df_sorted = df_interesse.sort_values("score_final", ascending=False).reset_index(drop=True)
    df_sorted["conversoes_acum"] = df_sorted["comprou"].cumsum()
    df_sorted["pct_base"] = (df_sorted.index + 1) / len(df_sorted) * 100
    df_sorted["pct_conversoes"] = df_sorted["conversoes_acum"] / df_sorted["comprou"].sum() * 100

    # Lift = % conversões capturadas / % base contatada
    df_sorted["lift_acum"] = df_sorted["pct_conversoes"] / df_sorted["pct_base"]

    ax2.plot(df_sorted["pct_base"], df_sorted["lift_acum"], linewidth=2, color="steelblue")
    ax2.axhline(1, color="red", linestyle="--", label="Sem modelo (lift=1)")
    ax2.set_xlabel("% da base contatada")
    ax2.set_ylabel("Lift acumulado")
    ax2.set_title("Curva de Lift")
    ax2.set_xlim(0, 100)
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    # Destacar lift nos primeiros 10%, 20%, 30%
    for pct in [10, 20, 30]:
        idx = int(len(df_sorted) * pct / 100)
        lift_val = df_sorted.iloc[idx]["lift_acum"]
        ax2.annotate(f"{pct}%: {lift_val:.2f}x",
                     xy=(pct, lift_val),
                     xytext=(pct + 5, lift_val + 0.1),
                     fontsize=9)

    # =========================================================================
    # 3. Curva de Ganho (Gains Chart)
    # =========================================================================
    ax3 = fig.add_subplot(2, 3, 3)

    ax3.plot(df_sorted["pct_base"], df_sorted["pct_conversoes"],
             linewidth=2, color="steelblue", label="Modelo")
    ax3.plot([0, 100], [0, 100], color="red", linestyle="--", label="Aleatório")
    ax3.fill_between(df_sorted["pct_base"], df_sorted["pct_conversoes"],
                     df_sorted["pct_base"], alpha=0.3, color="steelblue")
    ax3.set_xlabel("% da base contatada")
    ax3.set_ylabel("% das conversões capturadas")
    ax3.set_title("Curva de Ganho (Gains Chart)")
    ax3.set_xlim(0, 100)
    ax3.set_ylim(0, 100)
    ax3.legend(loc="lower right")
    ax3.grid(True, alpha=0.3)

    # Anotar ganho em pontos chave
    for pct in [20, 50]:
        idx = int(len(df_sorted) * pct / 100)
        ganho = df_sorted.iloc[idx]["pct_conversoes"]
        ax3.annotate(f"{pct}% base → {ganho:.0f}% conv.",
                     xy=(pct, ganho),
                     xytext=(pct + 5, ganho - 8),
                     fontsize=9)

    # =========================================================================
    # 4. Renda Média por Região (CEP-2)
    # =========================================================================
    ax4 = fig.add_subplot(2, 3, 4)

    renda_cep2 = (
        df_treino.groupby("cep2")
        .agg(
            renda_media=("intervalo_renda_num", "mean"),
            n=("cpf", "count")
        )
        .sort_values("renda_media", ascending=True)
    )

    cores = plt.cm.RdYlGn(np.linspace(0.1, 0.9, len(renda_cep2)))
    bars = ax4.barh(renda_cep2.index, renda_cep2["renda_media"], color=cores, edgecolor="black")
    ax4.set_xlabel("Renda média (1-5)")
    ax4.set_ylabel("Região (CEP-2)")
    ax4.set_title("Renda Média por Região")
    ax4.axvline(df_treino["intervalo_renda_num"].mean(), color="red", linestyle="--",
                label=f"Média geral: {df_treino['intervalo_renda_num'].mean():.2f}")
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis="x")

    # =========================================================================
    # 5. Taxa de Conversão por Faixa de Score
    # =========================================================================
    ax5 = fig.add_subplot(2, 3, 5)

    # Criar faixas de score
    bins = [0, 50, 60, 70, 80, 100]
    labels = ["0-50", "50-60", "60-70", "70-80", "80-100"]
    df_interesse["faixa_score"] = pd.cut(df_interesse["score_final"], bins=bins, labels=labels)

    conv_por_faixa = df_interesse.groupby("faixa_score", observed=True).agg(
        taxa=("comprou", "mean"),
        n=("cpf", "count")
    )

    cores_faixa = ["#d73027", "#fc8d59", "#fee08b", "#91cf60", "#1a9850"]
    bars = ax5.bar(range(len(conv_por_faixa)), conv_por_faixa["taxa"] * 100,
                   color=cores_faixa, edgecolor="black")
    ax5.set_xticks(range(len(conv_por_faixa)))
    ax5.set_xticklabels(conv_por_faixa.index)
    ax5.set_xlabel("Faixa de Score")
    ax5.set_ylabel("Taxa de conversão (%)")
    ax5.set_title("Conversão por Faixa de Score")
    ax5.axhline(df_interesse["comprou"].mean() * 100, color="red", linestyle="--", label="Baseline")
    ax5.legend()
    ax5.grid(True, alpha=0.3, axis="y")

    # Adicionar contagem em cada barra
    for i, (idx, row) in enumerate(conv_por_faixa.iterrows()):
        ax5.annotate(f"n={row['n']:,}", xy=(i, row['taxa'] * 100 + 0.2),
                     ha="center", fontsize=8)

    # =========================================================================
    # 6. Precision@K vs K
    # =========================================================================
    ax6 = fig.add_subplot(2, 3, 6)

    # Calcular precision para vários valores de K
    df_val_sorted = df_validacao.sort_values("score_final", ascending=False).reset_index(drop=True)
    df_val_sorted["alta_renda"] = (df_val_sorted["intervalo_renda_num"] >= 4).astype(int)

    baseline = df_val_sorted["alta_renda"].mean()
    ks = list(range(10, min(1001, len(df_val_sorted)), 10))
    precisions = []
    lifts = []

    for k in ks:
        prec = df_val_sorted.head(k)["alta_renda"].mean()
        precisions.append(prec * 100)
        lifts.append(prec / baseline if baseline > 0 else 0)

    ax6.plot(ks, precisions, linewidth=2, color="steelblue", label="Precision@K")
    ax6.axhline(baseline * 100, color="red", linestyle="--", label=f"Baseline: {baseline*100:.1f}%")
    ax6.set_xlabel("K (top leads)")
    ax6.set_ylabel("Precision (%)")
    ax6.set_title("Precision@K para Alta Renda")
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    ax6.set_xlim(0, max(ks))

    # =========================================================================
    # Finalizar
    # =========================================================================
    plt.tight_layout()
    plt.savefig("analises_adicionais.png", dpi=150)
    plt.show()
    print("Gráfico salvo: analises_adicionais.png")

    # =========================================================================
    # Calcular e printar métricas de ganho
    # =========================================================================
    print("\n" + "=" * 60)
    print("MÉTRICAS DE GANHO DO MODELO")
    print("=" * 60)

    total_conversoes = df_interesse["comprou"].sum()

    for pct in [10, 20, 30, 50]:
        idx = int(len(df_sorted) * pct / 100)
        conversoes_capturadas = df_sorted.iloc[:idx]["comprou"].sum()
        pct_capturado = conversoes_capturadas / total_conversoes * 100
        lift = pct_capturado / pct
        print(f"Top {pct:2d}% da base: captura {pct_capturado:.1f}% das conversões (lift {lift:.2f}x)")


# ============================================================================
# 4. Pipeline Principal
# ============================================================================

def carregar_dados():
    """Carrega e limpa os três CSVs."""
    # Forçar leitura de CPF e CEP como string para preservar zeros à esquerda
    interesse = pd.read_csv("interesse.csv", dtype={"cpf": str, "cep": str})
    formulario = pd.read_csv("formulario.csv", dtype={"cpf": str})
    compras = pd.read_csv("compras.csv", dtype={"cpf": str, "cep": str})

    # Limpeza
    interesse["cpf"] = interesse["cpf"].apply(limpar_cpf)
    interesse["cep"] = interesse["cep"].apply(limpar_cep)
    interesse = interesse.dropna(subset=["cpf", "cep"])

    formulario["cpf"] = formulario["cpf"].apply(limpar_cpf)
    formulario["intervalo_renda_num"] = formulario["intervalo_renda"].apply(mapear_renda)
    formulario = formulario.dropna(subset=["cpf", "intervalo_renda_num"])

    compras["cpf"] = compras["cpf"].apply(limpar_cpf)
    compras = compras.dropna(subset=["cpf"])

    print("Dados carregados:")
    print(f"  Interesse:  {len(interesse):,} leads")
    print(f"  Formulário: {len(formulario):,} respostas")
    print(f"  Compras:    {len(compras):,} conversões")

    return interesse, formulario, compras


def main():
    # 1. Carregar dados
    interesse, formulario, compras = carregar_dados()

    # 2. Preparar base de treino (FORMULÁRIO COMPLETO, não só compradores)
    #    Precisamos do CEP para treinar, então fazemos merge com interesse
    treino = formulario.merge(
        interesse[["cpf", "cep"]].drop_duplicates("cpf"),
        on="cpf",
        how="inner"
    )
    print(f"\nBase de treino (formulário com CEP): {len(treino):,}")

    # Split treino/validação (80/20)
    cpfs = treino["cpf"].unique()
    np.random.seed(42)
    np.random.shuffle(cpfs)

    n_valid = int(len(cpfs) * 0.2)
    cpfs_valid = set(cpfs[:n_valid])
    cpfs_treino = set(cpfs[n_valid:])

    treino_fit = treino[treino["cpf"].isin(cpfs_treino)].copy()
    validacao = treino[treino["cpf"].isin(cpfs_valid)].copy()

    # Adicionar níveis de CEP para visualizações
    treino_fit = adicionar_niveis_cep(treino_fit)

    print(f"  Treino:    {len(treino_fit):,}")
    print(f"  Validação: {len(validacao):,}")

    # 3. Treinar modelo
    print("\n" + "=" * 60)
    print("TREINAMENTO DO MODELO")
    print("=" * 60)

    modelo = ModeloRendaCEP()
    modelo.fit(treino_fit)

    # 4. Aplicar na validação e avaliar predição de renda
    validacao_scored = modelo.predict(validacao)
    avaliar_predicao_renda(validacao_scored)

    # 5. Aplicar na base de interesse (com flag de compra)
    cpfs_compraram = set(compras["cpf"].unique())
    interesse["comprou"] = interesse["cpf"].isin(cpfs_compraram).astype(int)

    interesse_scored = modelo.predict(interesse)

    # 6. Avaliar capacidade de prever conversão
    avaliar_conversao(interesse_scored)

    # 7. Gerar visualizações
    try:
        plotar_resultados(validacao_scored, interesse_scored)
        plotar_analises_adicionais(validacao_scored, interesse_scored, treino_fit)
    except Exception as e:
        print(f"\nNão foi possível gerar gráficos: {e}")

    # 8. Exportar
    colunas_export = [
        "cpf", "email", "cep", "data_interesse", "comprou",
        "cep5", "cep3", "cep2", "renda_estimada", "confianca",
        "nivel_usado", "score_final"
    ]
    colunas_export = [c for c in colunas_export if c in interesse_scored.columns]

    interesse_scored[colunas_export].to_csv("leads_scoreados.csv", index=False)
    print(f"\nExportado: leads_scoreados.csv ({len(interesse_scored):,} linhas)")


if __name__ == "__main__":
    main()